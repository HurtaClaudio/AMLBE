{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de Modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "location = r'data_gd.xlsm'\n",
    "\n",
    "X=pd.read_excel(location ,'Sheet1');X=X.values    #  ---> Si quiere tener la misma data de las láminas \n",
    "y=pd.read_excel(location ,'Sheet2');y=y.values   # ---> Si quiere tener la misma data de las láminas\n",
    "\n",
    "#X=2*np.random.rand(100,1) #--------->si quieren generar la data de cero\n",
    "#y=4+3*X+np.random.randn(100,1) # ---> si quieren generar la data de cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as s\n",
    "import numpy as np\n",
    "\n",
    "X_b=np.c_[np.ones((100,1)),X]\n",
    "n=float(len(X_b))\n",
    "k=float(int(X_b.shape[1]))\n",
    "theta_best=np.dot(np.dot(np.linalg.inv(np.dot(X_b.T,X_b)),X_b.T),y)\n",
    "y_est=np.dot(X_b,theta_best)\n",
    "y_prom=y_est.mean()\n",
    "r2=(np.dot(np.dot(theta_best.T,X_b.T),y)-n*y_prom**2)/(np.dot(y.T,y)-n*y_prom**2)\n",
    "r2atheil=1-(1-r2)*(n-1)/(n-k)\n",
    "r2agoldberger=(1-(k/n))*r2\n",
    "f_test=(r2/(k-1))/((1-r2)/(n - k))\n",
    "v=np.var(y-y_est)\n",
    "v_theta=np.linalg.inv(np.dot(X_b.T,X_b))*v\n",
    "sig_theta=np.sqrt(np.diag(v_theta)).reshape(len(v_theta),1)\n",
    "t_test=theta_best/sig_theta\n",
    "te=np.sqrt(v)\n",
    "\n",
    "ndc=0.05\n",
    "tc=s.t.ppf(1-ndc,n-k)\n",
    "fc=s.f.ppf(1-ndc,n-1,n-k)\n",
    "\n",
    "invtc=s.t.cdf(tc,n-k)\n",
    "invfc=s.f.cdf(fc,n-1,n-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "est = smf.OLS(y,X_b).fit()\n",
    "est.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X,y)\n",
    "plt.axis([0,2,0,15])\n",
    "plt.title('Data Generada')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1=pd.DataFrame(X)\n",
    "#df2=pd.DataFrame(y)\n",
    "#writer = pd.ExcelWriter('data_gd.xlsx', engine='xlsxwriter')\n",
    "#df1.to_excel(writer, sheet_name='Sheet1')\n",
    "#df2.to_excel(writer, sheet_name='Sheet2')\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=np.array([[0],[2]])\n",
    "X_new_b=np.c_[np.ones((2,1)),X_new]\n",
    "y_predict=np.dot(X_new_b,theta_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_new,y_predict,\"r-\")\n",
    "plt.plot(X,y,\"b.\")\n",
    "plt.axis([0,2,0,15])\n",
    "plt.title('Predicciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta=[]\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as m\n",
    "import numpy as np\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg=lin_reg.fit(X,y)\n",
    "theta.append(lin_reg.intercept_)\n",
    "theta.append(lin_reg.coef_)\n",
    "lin_reg.predict(X_new)\n",
    "y_est=lin_reg.predict(X)\n",
    "r2=m.r2_score(y,y_est)\n",
    "\n",
    "#yy = [ float(x) for x in y ]\n",
    "#yy_est = [ float(x) for x in y_est ]\n",
    "\n",
    "\n",
    "#f_test=m.fbeta_score(y,y_est,average=None, beta = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = np.linspace(-10, 10, 100)\n",
    "sig = 1 / (1 + np.exp(-t))\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot([-10, 10], [0, 0], \"k-\")\n",
    "plt.plot([-10, 10], [0.5, 0.5], \"k:\")\n",
    "plt.plot([-10, 10], [1, 1], \"k:\")\n",
    "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
    "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend(loc=\"upper left\", fontsize=20)\n",
    "plt.axis([-10, 10, -0.1, 1.1])\n",
    "plt.title(\"Gráfico de la Función Logística\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())\n",
    "print(iris.DESCR)\n",
    "\n",
    "X = iris[\"data\"][:, 3:]  # ancho de pétalo\n",
    "y = (iris[\"target\"] == 2).astype(np.int)  # 1 si Iris-Virginica, si no 0\n",
    "        \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(X[y==0], y[y==0], \"bs\")\n",
    "plt.plot(X[y==1], y[y==1], \"g^\")\n",
    "plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris-Virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"No Iris-Virginica\")\n",
    "plt.text(decision_boundary+0.02, 0.15, \"Limite de Decision\", fontsize=14, color=\"k\", ha=\"center\")\n",
    "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
    "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
    "plt.xlabel(\"Ancho de Petalo (cm)\", fontsize=14)\n",
    "plt.ylabel(\"Probabilidad\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 3, -0.02, 1.02])\n",
    "plt.title(\"Grafico Regresion Logistica\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
