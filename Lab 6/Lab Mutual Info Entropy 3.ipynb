{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Mutual Info Entropy 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #panda dataframes\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importo tabla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = r'Tabla_impago_full.xlsx'\n",
    "\n",
    "Tabla1 = pd.read_excel(Location,sheet_name=\"Tabla_B\")\n",
    "Tabla1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leo tabla ignoro los IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tabla1.iloc[:,2:]\n",
    "\n",
    "Xs=data.iloc[:,1:]\n",
    "Y=data.iloc[:,0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relleno los valores perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs=Xs.fillna(Xs.mean())\n",
    "Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-escalo las Xs para que funcione PCA y otros algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(Xs)\n",
    "Xs_res=scaler = scaler.transform(Xs)\n",
    "Xs_res=pd.DataFrame(data=Xs_res,index=Xs.index,columns=Xs.columns)\n",
    "Xs_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables usando Mínima Varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov=Xs_res.cov()\n",
    "correls=Xs.corr()\n",
    "sel = VarianceThreshold(threshold=0.01)\n",
    "filtered1_Xs=sel.fit_transform(Xs)\n",
    "filtered1_Xs=pd.DataFrame(data=filtered1_Xs,index=Xs.index,columns=Xs.columns)\n",
    "\n",
    "sel_cols1=sel.get_support(indices=True).T\n",
    "sel_cols1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de variables usando PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=17)\n",
    "pca.fit(Xs)\n",
    "evals=pca.explained_variance_                           # corresponde a los eigenvalues\n",
    "var_expl=pca.explained_variance_ratio_                  # Varianza explicada por cada componente principal \n",
    "evecs=pca.components_.T                                 # corresponde a los eigenvectores\n",
    "loadings=evecs*np.sqrt(evals)\n",
    "loadings_filt=np.where(np.abs(loadings)>0.3,loadings,float('nan'))\n",
    "loadings_filt=pd.DataFrame(data=loadings_filt,index=Xs.columns)\n",
    "loadings_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repito la operación, ahora con n factores que explican %de var total q quiero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=3)\n",
    "pca.fit(Xs)\n",
    "evals=pca.explained_variance_                           # corresponde a los eigenvalues\n",
    "var_expl=pca.explained_variance_ratio_                  # Varianza explicada por cada componente principal \n",
    "evecs=pca.components_.T                                 # corresponde a los eigenvectores\n",
    "loadings=evecs*np.sqrt(evals)\n",
    "loadings_filt=np.where(np.abs(loadings)>0.3,loadings,float('nan'))\n",
    "loadings_filt=pd.DataFrame(data=loadings_filt,index=Xs.columns)\n",
    "factores=pd.DataFrame(data=pca.fit_transform(Xs),columns=['factor1','factor2','factor3'])   \n",
    "factores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(factores, alpha=0.4, figsize=(6, 6), diagonal='hist')\n",
    "scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora selecciono variables en base a su información mutua respecto de la variable Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis=mutual_info_classif(Xs_res,Y)\n",
    "\n",
    "\n",
    "def Entropy(x,bins=0):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    df=pd.DataFrame(data=x)\n",
    "    \n",
    "      \n",
    "    if bins>0:\n",
    "        df['rangos']=pd.cut(df.iloc[:,0],bins)\n",
    "        count=df['rangos'].value_counts(sort=True)\n",
    "        probs=count/count.sum()\n",
    "        logs=np.log2(probs)\n",
    "        entropy=-probs*logs\n",
    "        entropy=entropy.sum()\n",
    "           \n",
    "    else:\n",
    "        count=df.iloc[:,0].value_counts(sort=True)\n",
    "        probs=count/count.sum()\n",
    "        logs=np.log2(probs)\n",
    "        entropy=-probs*logs\n",
    "        entropy=entropy.sum()\n",
    "    \n",
    "    return(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EntropiaXs_res=[]\n",
    "\n",
    "for equis in Xs_res:\n",
    "    EntropiaXs_res.append((equis,Entropy(Xs_res[equis],10)))\n",
    "\n",
    "EntropiaXs_Res=pd.DataFrame(data=EntropiaXs_res,columns=['variable','entropia'])\n",
    "IGR=pd.DataFrame()\n",
    "IGR['variable']=EntropiaXs_Res['variable']\n",
    "IGR['IGR']=mis/EntropiaXs_Res['entropia'].values\n",
    "IGR=IGR.sort_values(by='IGR',ascending=False)\n",
    "\n",
    "\n",
    "SelectKbest=SelectKBest(mutual_info_classif, k=4)\n",
    "Xs_sel=SelectKbest.fit_transform(Xs_res,Y)\n",
    "features = SelectKbest.get_support(indices=True).T\n",
    "\n",
    "Xs_sel2=Xs[Xs.columns[features]]\n",
    "Xs_sel2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora selecciono variables en base a su significancia estadística en una regresión lineal y=f(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectKbest2=SelectKBest(f_classif, k=4)\n",
    "Xs_sel3=SelectKbest2.fit_transform(Xs_res,Y)\n",
    "features2 = SelectKbest2.get_support(indices=True).T\n",
    "Xs_sel3=Xs[Xs.columns[features2]]\n",
    "Xs_sel3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
