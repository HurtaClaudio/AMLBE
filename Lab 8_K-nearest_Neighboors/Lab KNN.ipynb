{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #panda dataframes\n",
    "import numpy as np\n",
    "\n",
    "Location = r'Tabla_impago_full.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importo tabla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabla1 = pd.read_excel(Location,sheet_name=\"Tabla_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leo tabla ignoro los IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tabla1.iloc[:,2:]\n",
    "data=data.fillna(data.mean())\n",
    "\n",
    "data1=data.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando toda la data encontraré los vecinos más cercanos de cada fila (empresa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encuentro los k=2 vecinos más cercanos para cada fila en la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn me devuelve el índice de los k vecinos más cercanos y la distancia promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Además puedo pedir que me cree una matriz de adyacencia (vecinos más cercanos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizvecinos=nbrs.kneighbors_graph(data1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora ocuparé esta estrategia de los k-vecinos más cercanos para crear un modelo predictor de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separo la variable dependiente de las explicativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs=data.iloc[:,1:]\n",
    "Y=data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separo mi base de datos en dos muestras, una muestra de entrenamiento y una de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, Y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El comando KDTree leerá la base de datos de entrenamiento, y está será utilizada como mi \"modelo\"\n",
    "    Es decir cada vez que quiera predecir algo en la base de datos test, modeloknn buscará los más parecidos en la \n",
    "    base training y hará una proyección en base a eso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leo la base X_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloknn = KDTree(X_train.values, leaf_size=2)\n",
    "\n",
    "\n",
    "distancias= np.empty((0,2))\n",
    "indices= np.empty((0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Luego para cada fila en la base Train le voy buscando sus 2 vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for row in X_test.values:\n",
    "    counter=counter+1\n",
    "    print counter\n",
    "    row.reshape(1, -1)\n",
    "    dist, indx = modeloknn.query(row, k=2)     \n",
    "    distancias=np.vstack([distancias,dist])\n",
    "    indices=np.vstack([indices,indx])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn tiene una librería que realiza este proceso de manera automática\n",
    "    Es decir, me permite predecir la clase de un ejemplo usando como \"modelo\" los k-vecinos más cercanos\n",
    "    de una base de entrenamiento.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importaré la libreria de KNeighborsClassifier y las librerias que me permiten medir el ajuste del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuro el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn=KNeighborsClassifier(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lo entreno en la base train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Una vez entrenado primero lo ocupo para predecir en la base train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=clf_knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    En la base train, los valores de los k-vecinos más cercanos a una fila de esa misma base se ocupan para hacer la predicción.\n",
    "    Una vez que ya tengo las predicciones puedo calcular matriz de confusión, accuracy, recall, precision, auc, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=confusion_matrix(y_train,y_pred_train)\n",
    "\n",
    "acc_train=metrics.accuracy_score(y_train,y_pred_train)\n",
    "accuracy_train=clf_knn.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculo recall, precision, auc, fpr, tpr, etc en ambas bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, thresholds_train = metrics.roc_curve(y_train, y_pred_train, pos_label=1)\n",
    "auc_train=metrics.auc(fpr_train, tpr_train)\n",
    "recalls_train=recall_score(y_train, y_pred_train, average=None)\n",
    "preciss_train=precision_score(y_train, y_pred_train, average=None)\n",
    "f1sc_train=f1_score(y_train, y_pred_train, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora puedo usar el modelo para predecir en testing\n",
    "    Cada vez que quiera predecir algo en la base de datos test, clf_knn buscará los más parecidos \n",
    "    en la base training y hará una proyección en base a eso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=clf_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Una vez que ya tengo las predicciones puedo calcular matriz de confusión, accuracy, recall, precision, auc, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test=confusion_matrix(y_test,y_pred_test)\n",
    "\n",
    "acc_test=metrics.accuracy_score(y_test,y_pred_test)\n",
    "accuracy_test=clf_knn.score(X_test,y_test)\n",
    "\n",
    "fpr_test, tpr_test, thresholds_test = metrics.roc_curve(y_test, y_pred_test, pos_label=1)\n",
    "auc_test=metrics.auc(fpr_test, tpr_test)\n",
    "recalls_test=recall_score(y_test, y_pred_test, average=None)\n",
    "preciss_test=precision_score(y_test, y_pred_test, average=None)\n",
    "f1sc_test=f1_score(y_test, y_pred_test, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente haremos un proceso que usará dos modelos para predecir, uno con KNN y otro con regresión logística\n",
    "    Los resultados de aplicar los modelos en la muestra test quedaran guardados en la variable \"resultados_testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuro y parametrizo los modelos que voy a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    LogisticRegression()]\n",
    "\n",
    "resultados_testing=[] #genero una matriz vacia donde guardare los scores de los modelos Recall, Precision, AUC, etc\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train,y_train)\n",
    "    score_testing = clf.score(X_test, y_test)      #calculo scores en testing\n",
    "    pred_testing=clf.predict(X_test)               #predigo en base testing\n",
    "\n",
    "    #calculo recall, precision, auc, fpr, tpr, etc en ambas bases, reporto en vivo\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_testing, pos_label=1)\n",
    "\n",
    "    recalls=recall_score(y_test, pred_testing, average=None)\n",
    "    preciss=precision_score(y_test, pred_testing, average=None)\n",
    "    f1sc=f1_score(y_test, pred_testing, average=None)\n",
    "    auc1=metrics.auc(fpr, tpr)\n",
    "    resultados_testing.append((name,score_testing,recalls,preciss,f1sc,auc1))\n",
    "    colum = ['Name', 'Score', 'Recalls', 'Precision', 'f1sc', 'auc1']\n",
    "    resultados_testing2 = pd.DataFrame(resultados_testing, columns = colum)\n",
    "    \n",
    "    print(\"Hit Rates/Confusion Matrices en muestra testing:\")\n",
    "    print( resultados_testing2) \n",
    "    resultados_testing=[]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
