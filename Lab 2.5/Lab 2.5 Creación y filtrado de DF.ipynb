{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2,5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero importamos las librerías y definimos el UTF\n",
    "Además definimos la codificación utf-8 por que esta soporta el uso de acentos, y definimos el numero máximo de filas que se muestran cuando se abre un df (o cualquier objeto en python).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos un nuevo DataFrame\n",
    "Para crear un df necesitamos un vector con los nombres de las columnas, un vector con los indices, y una matriz con los valores.\n",
    "\n",
    "1. Creamos la variable `column_names`, que contiene los *nombres* de las columnas\n",
    "2. Luego creamos la variable `date_index`, que contiene los *indices* de nuestro df. En este caso corresponden a una fecha con una peridiocidad diaria, y no a algún número arbitrario.\n",
    "3. Definimos una matriz de dimensiones 6x4 de valores aleatorios y la llamamos `values`\n",
    "4. Definimos el DataFrame `df` con los vectores y matrices definidos en los puntos 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=['A','B','C','D']\n",
    "date_index=pd.date_range('20130101',periods=6,freq='D')\n",
    "values=np.random.rand(6,4)\n",
    "\n",
    "df=pd.DataFrame(values,date_index,column_names)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luego filtramos la matriz\n",
    "Para los **df** es necesario usar uno de los siguientes métodos:\n",
    "\n",
    "* Método .iloc    \n",
    "    `.iloc` es corto para *integer localization*, se usa para filtrar la matríz usando valores numéricos para el índice y las columnas.\n",
    "\n",
    "\n",
    "* Método .loc     \n",
    "    `.loc` es corto para *localization*, se usa para filtrar la matríz usando los *nombres de las columnas* y valores númericos para el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1=df.iloc[2:4,[0,3]]\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2=df.loc[:,['A','C']]\n",
    "aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_row=2\n",
    "start_col=2\n",
    "n=len(df)\n",
    "m=len(df.columns)\n",
    "aux3=df.iloc[start_row:n,start_col:m]\n",
    "aux3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos un nuevo DF\n",
    "\n",
    "Simulamos una base de datos que incluye el valor del cobre y el ipc, con una peridiocidad mensual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names2=['ipc','cobre']\n",
    "date_index2=pd.date_range('20130103',periods=6,freq='D')\n",
    "values2=np.random.rand(6,2)\n",
    "df2=pd.DataFrame(values2,date_index2,col_names2)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntamos ambos dataframes\n",
    "\n",
    "* Primero con el método de las matrices\n",
    "* Luego con el método concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[df,df2]\n",
    "df3=pd.concat(frames,axis=1)\n",
    "\n",
    "frames\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisamos métodos de extrapolación de valores ausentes (NaN)\n",
    "* Primero vemos que se pierde gran cantidad de información si esque simplemente se eliminan los NaN. Dado esto, es recomendable extrapolar los datos faltantes antes que perder la información.\n",
    "* Luego usamos el metodo *foward-fill* para extrapolar\n",
    "* Por último usamos el metodo *Backward-fill* para extrapolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux3=df.dropna()\n",
    "aux3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df3.fillna(method='ffill')\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df3.fillna(method='bfill')\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por último, hacemos un repaso de normalización de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "location = r'raw_data.xlsx'\n",
    "\n",
    "df=pd.read_excel(location)\n",
    "df= df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm=(df-df.mean(axis=0))/df.std(axis=0)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
