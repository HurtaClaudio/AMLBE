{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9 Decision Trees - balanceado - bagging - randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #panda dataframes\n",
    "\n",
    "Location = r'Tabla_impago_full.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importo tabla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabla1 = pd.read_excel(Location,sheet_name=\"Tabla_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leo tabla ignoro los IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tabla1.iloc[:,2:]\n",
    "data=data.fillna(data.mean())\n",
    "\n",
    "data1=data.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separo la variable dependiente de las explicativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs=data.iloc[:,1:]\n",
    "Y=data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separo mi base de datos en dos muestras, una muestra de entrenamiento y una de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, Y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "## balanceo muestra de entrenamiento - oversampling\n",
    "print('Balanceando Muestras ...'.format())+'\\n'\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))+'\\n'\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_reb, y_reb = ros.fit_sample(X_train, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_reb)))+'\\n'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "bags=RandomForestClassifier(n_estimators=10, n_jobs=1, verbose=1)\n",
    "\n",
    "bags.fit(X_reb,y_reb)\n",
    "\n",
    "estimators=bags.estimators_\n",
    "\n",
    "tree.export_graphviz(estimators[0],out_file='tree_balanced_1.dot')\n",
    "tree.export_graphviz(estimators[9],out_file='tree_balanced_10.dot')\n",
    "## se puede visualizar copiando y pegando el contenido del archivo .dot en http://www.webgraphviz.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicciones y probabilidades en la muestra de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=bags.predict(X_train)              #predicción\n",
    "probs_train=bags.predict_proba(X_train)          #probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculemos el ajuste accuracy del modelo en train y en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs2=bags.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Una vez que ya tengo las predicciones puedo calcular matriz de confusión, accuracy, recall, precision, auc, etc etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = bags.score(X_train, y_train) \n",
    "score_testing = bags.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para calcular otras métricas precision, recall, etc necesito también predecir en testing   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_testing=bags.predict(X_test)               #predigo en base testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculo recall, precision, auc, fpr, tpr, auc, f1 etc en ambas bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, thresholds_train = metrics.roc_curve(y_train, pred_train, pos_label=1)\n",
    "fpr_test, tpr_test, thresholds_test = metrics.roc_curve(y_test, pred_testing, pos_label=1)\n",
    "\n",
    "auc_train=metrics.auc(fpr_train, tpr_train)\n",
    "auc_test=metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "recalls_train=recall_score(y_train, pred_train, average=None)\n",
    "recalls_test=recall_score(y_test, pred_testing, average=None)\n",
    "\n",
    "precis_train=precision_score(y_train, pred_train, average=None)\n",
    "precis_test=precision_score(y_test, pred_testing, average=None)\n",
    "\n",
    "f1sc_train=f1_score(y_train, pred_train, average=None)\n",
    "f1sc_test=f1_score(y_test, pred_testing, average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
